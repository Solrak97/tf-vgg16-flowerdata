{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Solrak97/tf-vgg16-flowerdata/blob/main/VGG_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUk44wlBUSqO"
      },
      "source": [
        "# Transferencia de aprendizaje utilizando VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xj5_bnO3VsAq"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install kaggle torchmetrics wandb\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! rm -rf flowers\n",
        "! kaggle datasets download alxmamaev/flowers-recognition\n",
        "! unzip flowers-recognition.zip\n",
        "! rm -r flowers-recognition.zip\n",
        "! rm -rf flowers/sample_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zf79yxuCRcO-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "import pickle\n",
        "\n",
        "from torchmetrics import F1Score, Recall, Precision, Accuracy\n",
        "import wandb\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyOqFme5YBwM"
      },
      "source": [
        "## Carga del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eRkJOnpFSA7i"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
        "                                      transforms.ColorJitter(brightness=1, contrast=1, saturation=1),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                               ])\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((224,224)),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                               ])\n",
        "\n",
        "dataset = ImageFolder(\"flowers\")\n",
        "train, val = torch.utils.data.random_split(dataset, [4317 - 863, 863], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "train.dataset.transform = transform_train\n",
        "val.dataset.transform = transform\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(train, batch_size=200, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(val, batch_size = 200, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ip5eZ-6OSVsg"
      },
      "outputs": [],
      "source": [
        "def im_convert(tensor):\n",
        "  image = tensor.cpu().clone().detach().numpy()\n",
        "  image = image.transpose(1, 2, 0)\n",
        "  image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n",
        "  image = image.clip(0, 1)\n",
        "  return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywZj89_xTyUk"
      },
      "source": [
        "## Modificación del modelo base VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4QtN8tcYSZCo"
      },
      "outputs": [],
      "source": [
        "classes = ('margaritas', 'rosas', 'dientes de león', 'tulipanes', 'girasoles')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQuEWoCyScV_",
<<<<<<< HEAD
        "outputId": "45f9c6c6-1d0b-40d8-ec0a-80e4ead7a83a"
=======
        "outputId": "421afc0a-6c78-446e-e007-93fe2589b6c9"
>>>>>>> 1bdd752f3dc3937709fa53e9d06a701bde9982ea
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Creación del modelo VGG16\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Congelamiento del modelo base\n",
        "for param in model.features.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "n_inputs = model.classifier[6].in_features\n",
        "last_layer = nn.Linear(n_inputs, len(classes))\n",
        "\n",
        "# Reemplzo de la capa de salida\n",
        "model.classifier[6] = last_layer\n",
        "#model.classifier.append(nn.Softmax())\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW2OLHbEbKBG"
      },
      "source": [
        "## Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5isVa-FPbLzX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "b9c01c59-f951-4d96-f35f-d775669884be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msolrak\u001b[0m (\u001b[33mpanas\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220718_040152-1bett5dd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/panas/Clasificador%20de%20plantas/runs/1bett5dd\" target=\"_blank\">desert-donkey-2</a></strong> to <a href=\"https://wandb.ai/panas/Clasificador%20de%20plantas\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/panas/Clasificador%20de%20plantas/runs/1bett5dd?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f731b009490>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "\n",
        "wandb.init(project=\"Clasificador de plantas\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYHw0ViGbYsT",
<<<<<<< HEAD
        "outputId": "773f0217-beac-4279-e031-c0718b50b3f9"
=======
        "outputId": "85a027f5-f79c-4013-b87c-e46ecd8a08f8"
>>>>>>> 1bdd752f3dc3937709fa53e9d06a701bde9982ea
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
<<<<<<< HEAD
            "{'Validation Accuracy': tensor(0.8500, device='cuda:0'), 'F1 Score': tensor(0.8500, device='cuda:0'), 'Recall': tensor(0.8425, device='cuda:0'), 'Precision': tensor(0.8571, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8350, device='cuda:0'), 'F1 Score': tensor(0.8350, device='cuda:0'), 'Recall': tensor(0.8366, device='cuda:0'), 'Precision': tensor(0.8340, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8250, device='cuda:0'), 'F1 Score': tensor(0.8250, device='cuda:0'), 'Recall': tensor(0.8166, device='cuda:0'), 'Precision': tensor(0.8167, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8500, device='cuda:0'), 'F1 Score': tensor(0.8500, device='cuda:0'), 'Recall': tensor(0.8382, device='cuda:0'), 'Precision': tensor(0.8419, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8730, device='cuda:0'), 'F1 Score': tensor(0.8730, device='cuda:0'), 'Recall': tensor(0.8660, device='cuda:0'), 'Precision': tensor(0.8944, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8750, device='cuda:0'), 'F1 Score': tensor(0.8750, device='cuda:0'), 'Recall': tensor(0.8696, device='cuda:0'), 'Precision': tensor(0.8911, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8550, device='cuda:0'), 'F1 Score': tensor(0.8550, device='cuda:0'), 'Recall': tensor(0.8557, device='cuda:0'), 'Precision': tensor(0.8543, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8400, device='cuda:0'), 'F1 Score': tensor(0.8400, device='cuda:0'), 'Recall': tensor(0.8492, device='cuda:0'), 'Precision': tensor(0.8391, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8800, device='cuda:0'), 'F1 Score': tensor(0.8800, device='cuda:0'), 'Recall': tensor(0.8691, device='cuda:0'), 'Precision': tensor(0.8753, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8889, device='cuda:0'), 'F1 Score': tensor(0.8889, device='cuda:0'), 'Recall': tensor(0.8844, device='cuda:0'), 'Precision': tensor(0.9027, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8850, device='cuda:0'), 'F1 Score': tensor(0.8850, device='cuda:0'), 'Recall': tensor(0.8869, device='cuda:0'), 'Precision': tensor(0.8898, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8600, device='cuda:0'), 'F1 Score': tensor(0.8600, device='cuda:0'), 'Recall': tensor(0.8625, device='cuda:0'), 'Precision': tensor(0.8558, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8550, device='cuda:0'), 'F1 Score': tensor(0.8550, device='cuda:0'), 'Recall': tensor(0.8565, device='cuda:0'), 'Precision': tensor(0.8510, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.9000, device='cuda:0'), 'F1 Score': tensor(0.9000, device='cuda:0'), 'Recall': tensor(0.9010, device='cuda:0'), 'Precision': tensor(0.8956, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8889, device='cuda:0'), 'F1 Score': tensor(0.8889, device='cuda:0'), 'Recall': tensor(0.8862, device='cuda:0'), 'Precision': tensor(0.8942, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8900, device='cuda:0'), 'F1 Score': tensor(0.8900, device='cuda:0'), 'Recall': tensor(0.8883, device='cuda:0'), 'Precision': tensor(0.8922, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8600, device='cuda:0'), 'F1 Score': tensor(0.8600, device='cuda:0'), 'Recall': tensor(0.8602, device='cuda:0'), 'Precision': tensor(0.8570, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8500, device='cuda:0'), 'F1 Score': tensor(0.8500, device='cuda:0'), 'Recall': tensor(0.8507, device='cuda:0'), 'Precision': tensor(0.8415, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8950, device='cuda:0'), 'F1 Score': tensor(0.8950, device='cuda:0'), 'Recall': tensor(0.8952, device='cuda:0'), 'Precision': tensor(0.8923, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8889, device='cuda:0'), 'F1 Score': tensor(0.8889, device='cuda:0'), 'Recall': tensor(0.8862, device='cuda:0'), 'Precision': tensor(0.8986, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8800, device='cuda:0'), 'F1 Score': tensor(0.8800, device='cuda:0'), 'Recall': tensor(0.8807, device='cuda:0'), 'Precision': tensor(0.8802, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8550, device='cuda:0'), 'F1 Score': tensor(0.8550, device='cuda:0'), 'Recall': tensor(0.8534, device='cuda:0'), 'Precision': tensor(0.8506, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8550, device='cuda:0'), 'F1 Score': tensor(0.8550, device='cuda:0'), 'Recall': tensor(0.8601, device='cuda:0'), 'Precision': tensor(0.8478, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8750, device='cuda:0'), 'F1 Score': tensor(0.8750, device='cuda:0'), 'Recall': tensor(0.8694, device='cuda:0'), 'Precision': tensor(0.8791, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.9048, device='cuda:0'), 'F1 Score': tensor(0.9048, device='cuda:0'), 'Recall': tensor(0.9044, device='cuda:0'), 'Precision': tensor(0.9094, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.9100, device='cuda:0'), 'F1 Score': tensor(0.9100, device='cuda:0'), 'Recall': tensor(0.9099, device='cuda:0'), 'Precision': tensor(0.9102, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8700, device='cuda:0'), 'F1 Score': tensor(0.8700, device='cuda:0'), 'Recall': tensor(0.8725, device='cuda:0'), 'Precision': tensor(0.8653, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8450, device='cuda:0'), 'F1 Score': tensor(0.8450, device='cuda:0'), 'Recall': tensor(0.8555, device='cuda:0'), 'Precision': tensor(0.8381, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.9050, device='cuda:0'), 'F1 Score': tensor(0.9050, device='cuda:0'), 'Recall': tensor(0.9030, device='cuda:0'), 'Precision': tensor(0.8977, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.9048, device='cuda:0'), 'F1 Score': tensor(0.9048, device='cuda:0'), 'Recall': tensor(0.9044, device='cuda:0'), 'Precision': tensor(0.9094, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.9050, device='cuda:0'), 'F1 Score': tensor(0.9050, device='cuda:0'), 'Recall': tensor(0.9078, device='cuda:0'), 'Precision': tensor(0.9069, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8650, device='cuda:0'), 'F1 Score': tensor(0.8650, device='cuda:0'), 'Recall': tensor(0.8681, device='cuda:0'), 'Precision': tensor(0.8585, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8350, device='cuda:0'), 'F1 Score': tensor(0.8350, device='cuda:0'), 'Recall': tensor(0.8394, device='cuda:0'), 'Precision': tensor(0.8270, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8850, device='cuda:0'), 'F1 Score': tensor(0.8850, device='cuda:0'), 'Recall': tensor(0.8828, device='cuda:0'), 'Precision': tensor(0.8771, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8571, device='cuda:0'), 'F1 Score': tensor(0.8571, device='cuda:0'), 'Recall': tensor(0.8529, device='cuda:0'), 'Precision': tensor(0.8640, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8850, device='cuda:0'), 'F1 Score': tensor(0.8850, device='cuda:0'), 'Recall': tensor(0.8813, device='cuda:0'), 'Precision': tensor(0.8966, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8750, device='cuda:0'), 'F1 Score': tensor(0.8750, device='cuda:0'), 'Recall': tensor(0.8648, device='cuda:0'), 'Precision': tensor(0.8728, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8250, device='cuda:0'), 'F1 Score': tensor(0.8250, device='cuda:0'), 'Recall': tensor(0.8267, device='cuda:0'), 'Precision': tensor(0.8214, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8950, device='cuda:0'), 'F1 Score': tensor(0.8950, device='cuda:0'), 'Recall': tensor(0.8935, device='cuda:0'), 'Precision': tensor(0.8912, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.9206, device='cuda:0'), 'F1 Score': tensor(0.9206, device='cuda:0'), 'Recall': tensor(0.9192, device='cuda:0'), 'Precision': tensor(0.9346, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.9100, device='cuda:0'), 'F1 Score': tensor(0.9100, device='cuda:0'), 'Recall': tensor(0.9105, device='cuda:0'), 'Precision': tensor(0.9120, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8600, device='cuda:0'), 'F1 Score': tensor(0.8600, device='cuda:0'), 'Recall': tensor(0.8608, device='cuda:0'), 'Precision': tensor(0.8540, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8550, device='cuda:0'), 'F1 Score': tensor(0.8550, device='cuda:0'), 'Recall': tensor(0.8634, device='cuda:0'), 'Precision': tensor(0.8474, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8850, device='cuda:0'), 'F1 Score': tensor(0.8850, device='cuda:0'), 'Recall': tensor(0.8760, device='cuda:0'), 'Precision': tensor(0.8830, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.9048, device='cuda:0'), 'F1 Score': tensor(0.9048, device='cuda:0'), 'Recall': tensor(0.9010, device='cuda:0'), 'Precision': tensor(0.9078, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8850, device='cuda:0'), 'F1 Score': tensor(0.8850, device='cuda:0'), 'Recall': tensor(0.8811, device='cuda:0'), 'Precision': tensor(0.8918, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8650, device='cuda:0'), 'F1 Score': tensor(0.8650, device='cuda:0'), 'Recall': tensor(0.8636, device='cuda:0'), 'Precision': tensor(0.8595, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8450, device='cuda:0'), 'F1 Score': tensor(0.8450, device='cuda:0'), 'Recall': tensor(0.8480, device='cuda:0'), 'Precision': tensor(0.8350, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8750, device='cuda:0'), 'F1 Score': tensor(0.8750, device='cuda:0'), 'Recall': tensor(0.8638, device='cuda:0'), 'Precision': tensor(0.8705, device='cuda:0')}\n",
            "{'Validation Accuracy': tensor(0.8730, device='cuda:0'), 'F1 Score': tensor(0.8730, device='cuda:0'), 'Recall': tensor(0.8677, device='cuda:0'), 'Precision': tensor(0.8788, device='cuda:0')}\n"
=======
            "epoch : 1\n",
            "training loss: 0.0040, acc 0.7131 \n",
            "validation loss: 0.0025, validation acc 0.8366 \n",
            "epoch : 2\n",
            "training loss: 0.0014, acc 0.9062 \n",
            "validation loss: 0.0021, validation acc 0.8563 \n",
            "epoch : 3\n",
            "training loss: 0.0006, acc 0.9647 \n",
            "validation loss: 0.0022, validation acc 0.8702 \n",
            "epoch : 4\n",
            "training loss: 0.0003, acc 0.9858 \n",
            "validation loss: 0.0023, validation acc 0.8737 \n",
            "epoch : 5\n",
            "training loss: 0.0002, acc 0.9933 \n",
            "validation loss: 0.0023, validation acc 0.8749 \n",
            "epoch : 6\n",
            "training loss: 0.0001, acc 0.9977 \n",
            "validation loss: 0.0026, validation acc 0.8598 \n",
            "epoch : 7\n",
            "training loss: 0.0001, acc 0.9986 \n",
            "validation loss: 0.0024, validation acc 0.8714 \n",
            "epoch : 8\n",
            "training loss: 0.0000, acc 0.9991 \n",
            "validation loss: 0.0029, validation acc 0.8691 \n",
            "epoch : 9\n",
            "training loss: 0.0000, acc 0.9988 \n",
            "validation loss: 0.0026, validation acc 0.8737 \n",
            "epoch : 10\n",
            "training loss: 0.0000, acc 0.9994 \n",
            "validation loss: 0.0028, validation acc 0.8656 \n"
>>>>>>> 1bdd752f3dc3937709fa53e9d06a701bde9982ea
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "running_loss_history = []\n",
        "running_corrects_history = []\n",
        "val_running_loss_history = []\n",
        "val_running_corrects_history = []\n",
        "\n",
        "\n",
        "f1 = F1Score(num_classes=5).to(device)\n",
        "recall = Recall(average='macro', num_classes=5).to(device)\n",
        "precision = Precision(average='macro', num_classes=5).to(device)\n",
        "accuracy = Accuracy().to(device)\n",
        "\n",
        "\n",
        "for e in range(epochs):\n",
        "  \n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0.0\n",
        "  val_running_loss = 0.0\n",
        "  val_running_corrects = 0.0\n",
        "  \n",
        "  for inputs, labels in training_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    running_loss += loss.item()\n",
        "    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "  else:\n",
        "    with torch.no_grad():\n",
        "      for val_inputs, val_labels in validation_loader:\n",
        "        val_inputs = val_inputs.to(device)\n",
        "        val_labels = val_labels.to(device)\n",
        "        val_outputs = model(val_inputs)\n",
        "        val_loss = criterion(val_outputs, val_labels)\n",
        "\n",
        "        _, val_preds = torch.max(val_outputs, 1)\n",
        "        val_running_loss += val_loss.item()\n",
        "        val_running_corrects += torch.sum(val_preds == val_labels.data)\n",
        "\n",
        "        wandb.log({'Validation Accuracy': accuracy(val_outputs, val_labels), 'F1 Score': f1(\n",
        "          val_outputs, val_labels), 'Recall': recall(val_outputs, val_labels), 'Precision': precision(val_outputs, val_labels)})\n",
        "\n",
        "        print({'Validation Accuracy': accuracy(val_outputs, val_labels), 'F1 Score': f1(\n",
        "          val_outputs, val_labels), 'Recall': recall(val_outputs, val_labels), 'Precision': precision(val_outputs, val_labels)})\n",
        "    \n",
        "      \n",
        "    epoch_loss = running_loss/len(training_loader.dataset)\n",
        "    epoch_acc = running_corrects.float()/ len(training_loader.dataset)\n",
        "    running_loss_history.append(epoch_loss)\n",
        "    running_corrects_history.append(epoch_acc)\n",
        "    \n",
        "    val_epoch_loss = val_running_loss/len(validation_loader.dataset)\n",
        "    val_epoch_acc = val_running_corrects.float()/ len(validation_loader.dataset)\n",
        "    val_running_loss_history.append(val_epoch_loss)\n",
        "    val_running_corrects_history.append(val_epoch_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEh89BxZC0ox"
      },
      "source": [
        "## Guardar modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "abT40udzHcFT"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, path):\n",
<<<<<<< HEAD
        "    # Basic details\n",
        "    checkpoint = {\n",
        "        'class_to_idx': model.class_to_idx,\n",
        "        'idx_to_class': model.idx_to_class,\n",
        "        'epochs': model.epochs,\n",
        "    }\n",
        "\n",
        "    # Extract the final classifier and the state dictionary\n",
        "    \n",
        "    # Check to see if model was parallelized\n",
        "    if torch.cuda.is_available():\n",
        "      if torch.cuda.device_count() > 1:\n",
        "        checkpoint['classifier'] = model.module.classifier\n",
        "        checkpoint['state_dict'] = model.module.state_dict()\n",
        "\n",
        "    else:\n",
        "       checkpoint['classifier'] = model.classifier\n",
        "       checkpoint['state_dict'] = model.state_dict()\n",
        "\n",
        "    # Add the optimizer\n",
        "    checkpoint['optimizer'] = model.optimizer\n",
        "    checkpoint['optimizer_state_dict'] = model.optimizer.state_dict()\n",
        "\n",
        "    # Save the data to the path\n",
        "    torch.save(checkpoint, path)"
=======
        "    # Extract the final classifier and the state dictionary\n",
        "    \n",
        "    state = {}\n",
        "\n",
        "    # Check to see if model was parallelized\n",
        "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
        "        state['classifier'] = model.module.classifier\n",
        "        state['state_dict'] = model.module.state_dict()\n",
        "\n",
        "    else:\n",
        "       state['classifier'] = model.classifier\n",
        "       state['state_dict'] = model.state_dict()\n",
        "\n",
        "    # Save the data to the path\n",
        "    torch.save(state, path)"
>>>>>>> 1bdd752f3dc3937709fa53e9d06a701bde9982ea
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv6ijtpdHeSi"
      },
      "source": [
        "## Cargar modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GS3o_N-RHfwk"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(path, device):\n",
        "\n",
        "    # Load in checkpoint\n",
        "    state = torch.load(path, map_location=torch.device('cpu'))\n",
        "\n",
        "    # Non trainable model\n",
        "    model = models.vgg16(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "\n",
        "    # Load in the state dict\n",
        "    model.classifier = state['classifier']\n",
        "    model.load_state_dict(state['state_dict'])\n",
        "\n",
<<<<<<< HEAD
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f'{total_params:,} total parameters.')\n",
        "    total_trainable_params = sum(\n",
        "        p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f'{total_trainable_params:,} total gradient parameters.')\n",
        "\n",
        "    # Move to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Model basics\n",
        "    model.class_to_idx = checkpoint['class_to_idx']\n",
        "    model.idx_to_class = checkpoint['idx_to_class']\n",
        "    model.epochs = checkpoint['epochs']\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = checkpoint['optimizer']\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    return model, optimizer"
=======
        "    return model.to(device)"
>>>>>>> 1bdd752f3dc3937709fa53e9d06a701bde9982ea
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
<<<<<<< HEAD
        "id": "tlbJgcIUC25T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "f5c719b5-f8b3-4b24-ab9b-aacfc2c8e565"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1ce90ae5703c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classifier.trch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'classifier.trch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e8ed83b59f4e>\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(model, path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Basic details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     checkpoint = {\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;34m'class_to_idx'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;34m'idx_to_class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx_to_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m'epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1206\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1208\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'VGG' object has no attribute 'class_to_idx'"
          ]
=======
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlbJgcIUC25T",
        "outputId": "db31fd40-22b6-4c9f-a6df-fa013c1cc135"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
>>>>>>> 1bdd752f3dc3937709fa53e9d06a701bde9982ea
        }
      ],
      "source": [
        "save_checkpoint(model, 'classifier.trch')\n",
        "load_checkpoint('classifier.trch', device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
<<<<<<< HEAD
      "name": "VGG_TF.ipynb",
=======
      "include_colab_link": true,
      "name": "VGG-TF.ipynb",
>>>>>>> 1bdd752f3dc3937709fa53e9d06a701bde9982ea
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.5 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
<<<<<<< HEAD
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "e11061b56a27d33310e4eb7b3a307ea92e5c0cf781e8f02a667554945f7085cc"
=======
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "07498890263c38a1c095232e2a086cf5383785c7f0d36a597f37f80ed3bdc2da"
>>>>>>> 1bdd752f3dc3937709fa53e9d06a701bde9982ea
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}